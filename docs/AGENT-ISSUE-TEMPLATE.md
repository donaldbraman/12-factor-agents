# ðŸ¤– Autonomous Agent Implementation Guide
### GitHub Issue â†’ Framework Pipeline Template

## ðŸŽ¯ Framework Context & Capabilities

You are an autonomous implementation agent working within the **12-factor-agents framework**, a production-proven system with:

### Core Capabilities
- **Hierarchical Orchestration**: Multi-level task delegation (Primary â†’ Secondary â†’ Tertiary)
  - Measured performance: 0.2% coordination overhead (target <5%)
  - Successfully coordinated 13+ agents in production
  - Handles 10x task complexity vs single agents
  
- **Autonomous Background Execution**: True non-blocking operation
  - Pattern proven with Issues #35, #36, #37 simultaneous implementation
  - Status file monitoring for progress tracking
  - Crash-safe execution with timeout protection

- **5 Coordination Patterns**: 
  - **MapReduce**: Distribute work, aggregate results (e.g., processing 1000+ files)
  - **Pipeline**: Sequential processing (e.g., parse â†’ validate â†’ transform â†’ store)
  - **Fork-Join**: Parallel execution with sync (e.g., independent test suites)
  - **Scatter-Gather**: Broadcast & collect (e.g., multi-agent consensus)
  - **Saga**: Transactional with rollback (e.g., deployment workflows)

### Proven Performance Metrics
- âœ… 45% Framework Enhancement achieved
- âœ… 95% Context Efficiency (up from 60% baseline)
- âœ… 100+ Agent Coordination capability
- âœ… 75% Memory Reduction per agent
- âœ… 200% Faster Workflows via parallelization

## ðŸ“‹ Your Mission
Implement GitHub issue #[NUMBER]: [TITLE]

### Pre-flight Checklist
- [ ] Issue exists in GitHub repository
- [ ] You have necessary repository access
- [ ] Framework is properly initialized
- [ ] Previous related issues reviewed

## Framework Patterns to Follow

### 1. Autonomous Background Execution (REQUIRED)
```python
# Create autonomous agent script
Write("scripts/autonomous_[feature]_agent.py", agent_code)
bash_id = Bash("nohup uv run scripts/autonomous_[feature]_agent.py > /tmp/agent.log 2>&1 &", 
               run_in_background=True)

# Monitor via status files
def update_status(progress: int, message: str, data: dict = None):
    status = {
        "agent_id": self.agent_id,
        "issue": issue_number,
        "progress": progress,
        "message": message,
        "data": data or {},
        "timestamp": datetime.now().isoformat(),
        "pid": os.getpid()
    }
    Path(f"/tmp/{self.agent_id}_status.json").write_text(json.dumps(status, indent=2))
```

### 2. Task Complexity Analysis & Pattern Selection

#### Complexity Assessment
Analyze your task to determine the appropriate approach:

| Complexity | Indicators | Pattern | Agent Count |
|------------|-----------|---------|-------------|
| **ATOMIC** | Single file edit, simple fix | Direct execution | 1 |
| **SIMPLE** | Add feature, update component | Direct execution | 1 |
| **MODERATE** | Test suite, validation pipeline | Fork-Join or Pipeline | 2-5 |
| **COMPLEX** | Integration, multi-component | MapReduce or Scatter-Gather | 5-15 |
| **ENTERPRISE** | System migration, architecture | Hierarchical + Saga | 15-100+ |

#### Pattern Selection Guide
```python
# Decision tree for pattern selection
if task_involves_sequential_steps:
    use_pattern = OrchestrationPattern.PIPELINE
elif task_requires_aggregation:
    use_pattern = OrchestrationPattern.MAPREDUCE
elif task_needs_consensus:
    use_pattern = OrchestrationPattern.SCATTER_GATHER
elif task_requires_rollback:
    use_pattern = OrchestrationPattern.SAGA
else:  # Independent parallel tasks
    use_pattern = OrchestrationPattern.FORK_JOIN
```

#### Real Example from Production
```python
# Issue #37: Agent Marketplace (COMPLEX)
# Used Fork-Join for parallel component development
components = [
    "plugin_system",      # Tertiary Agent 1
    "agent_registry",     # Tertiary Agent 2
    "marketplace_ui",     # Tertiary Agent 3
    "security_framework"  # Tertiary Agent 4
]
# Result: All components developed in parallel, 100% completion
```

### 3. Implementation Structure
```
12-factor-agents/
â”œâ”€â”€ core/                  # Core functionality goes here
â”‚   â””â”€â”€ [your_module]/     # New feature modules
â”œâ”€â”€ agents/                # Reusable agent implementations
â”œâ”€â”€ tests/                 # Comprehensive test coverage
â”‚   â”œâ”€â”€ unit/             
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ performance/       # Include benchmarks
â”œâ”€â”€ docs/                  # Documentation (only if requested)
â””â”€â”€ scripts/               # Automation scripts
```

## Implementation Workflow

### Phase 1: Issue Analysis & Planning
1. Read the GitHub issue completely: `gh issue view [NUMBER]`
2. Analyze complexity using TaskComplexity patterns
3. Determine if hierarchical orchestration is needed (3+ steps = use orchestration)
4. Create implementation plan with clear phases

### Phase 2: Autonomous Implementation
1. Create feature branch: `feature/[description]-issue-[NUMBER]`
2. Implement following 12-factor principles:
   - Own your prompts (externalize configuration)
   - Own your context window (95% efficiency target)
   - Tools return structured ToolResponse
   - Small, focused agents (single responsibility)
3. Follow existing patterns in the codebase
4. Use `uv` for all Python operations

### Phase 3: Testing & Validation
```python
# Required validations
- Unit tests in tests/test_[feature].py
- Performance benchmarks if applicable
- Integration tests for complex features
- Validate performance claims:
  * Context efficiency (target: 95%)
  * Coordination overhead (target: <5%)
  * Memory usage (target: <500MB per agent)
```

### Phase 4: Git Workflow
```bash
# Commit with descriptive message
git commit -m "feat: [Description] (#[NUMBER])

- [Component 1]: What was implemented
- [Component 2]: What was implemented
- [Tests]: Coverage added
- [Performance]: Metrics achieved

ðŸ¤– Generated with Claude Code
Co-Authored-By: Claude <noreply@anthropic.com>"

# Create PR
gh pr create --title "feat: [Description] (#[NUMBER])" \
  --body "[Comprehensive description with metrics]"
```

## Safety Requirements (CRITICAL for Performance/Testing)
If implementing benchmarks or tests that could crash:
```python
# Use timeout protection
signal.signal(signal.SIGALRM, timeout_handler)
signal.alarm(30)  # 30 second maximum

try:
    # Your potentially dangerous code
    result = run_benchmark()
except (TimeoutError, Exception) as e:
    print(f"ðŸ›¡ï¸ Safely handled: {e}")
finally:
    signal.alarm(0)  # Cancel timeout
```

## Success Metrics
Your implementation should achieve:
- âœ… Clean code following repository patterns
- âœ… Comprehensive test coverage
- âœ… Performance validation (if applicable)
- âœ… Successful PR creation
- âœ… No blocking operations (use background execution)

## ðŸ” Troubleshooting Guide

### Common Issues & Solutions

| Issue | Symptom | Solution |
|-------|---------|----------|
| **Agent Timeout** | Task exceeds 30s | Use background execution with status monitoring |
| **Memory Overflow** | >500MB per agent | Implement streaming/chunking, use MapReduce |
| **Coordination Overhead** | >5% overhead | Reduce hierarchy depth, optimize task decomposition |
| **Test Failures** | Benchmarks crash | Wrap in timeout protection (see Safety Requirements) |
| **Context Loss** | Agent forgets state | Use status files and checkpointing |

### Debug Commands
```bash
# Check agent status
cat /tmp/*_agent_*_status.json | jq '.'

# Monitor background processes
ps aux | grep autonomous_

# View orchestration hierarchy
uv run -c "from core.hierarchical_orchestrator import HierarchicalOrchestrator; 
o = HierarchicalOrchestrator(); print(o.get_agent_hierarchy())"

# Check performance metrics
cat /tmp/orchestration_status/*.json | jq '.coordination_overhead'
```

## ðŸ“š Concrete Examples

### Example 1: Simple Feature Addition (SIMPLE complexity)
```
"Create GitHub issue #41 to add a retry mechanism to the agent executor. 
The feature should retry failed tasks up to 3 times with exponential backoff."

Expected approach: Direct implementation, no orchestration needed
```

### Example 2: Testing Suite Implementation (MODERATE complexity)
```
"Create GitHub issue #42 to implement comprehensive integration tests for 
the hierarchical orchestrator. Tests should cover all 5 coordination patterns, 
validate performance claims, and include stress testing."

Expected approach: Fork-Join pattern with 5 parallel test agents
```

### Example 3: System Refactoring (ENTERPRISE complexity)
```
"Create GitHub issue #43 to refactor the entire agent communication system 
to use event-driven architecture. This should maintain backward compatibility, 
improve performance by 30%, and support 500+ concurrent agents."

Expected approach: Hierarchical orchestration with Saga pattern for rollback capability
```

## âœ… Success Criteria & Return Format

### What Constitutes Success
- [ ] All tests pass (unit, integration, performance)
- [ ] Performance targets met or exceeded
- [ ] Clean code following repository patterns
- [ ] PR created and CI checks pass
- [ ] No blocking operations introduced

### Required Return Information
```json
{
  "pr_url": "https://github.com/org/repo/pull/XX",
  "issue_number": 40,
  "implementation_summary": {
    "components_created": ["module1", "module2"],
    "tests_added": 15,
    "documentation_updated": true
  },
  "performance_metrics": {
    "execution_time": "0.003s",
    "coordination_overhead": "0.2%",
    "memory_usage": "234MB",
    "agents_coordinated": 7
  },
  "validation_results": {
    "unit_tests": "15/15 passed",
    "integration_tests": "8/8 passed",
    "performance_benchmarks": "all targets met"
  },
  "challenges_resolved": [
    "Initial timeout issue resolved with background execution",
    "Memory optimization achieved through streaming"
  ]
}
```

## ðŸš€ Final Reminders

1. **Always use background execution** for tasks >5 seconds
2. **Monitor progress** via status files, not blocking waits
3. **Follow CLAUDE.md** rules strictly
4. **Test with timeouts** to prevent crashes
5. **Leverage existing patterns** - don't reinvent the wheel
6. **Document only when requested** - code should be self-explanatory

**Remember**: The framework has already proven it can handle 3 complex issues simultaneously with 0.2% overhead. Use its full power!